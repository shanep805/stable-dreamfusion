{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shanep805/stable-dreamfusion/blob/main/Copy_of_stable_dreamfusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVDV5YJ9Ngdw"
      },
      "source": [
        "# Example usage of [stable-dreamfusion](https://github.com/ashawkey/stable-dreamfusion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od2eF2ZwH_6W"
      },
      "source": [
        "### Check the machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfirUQVeMvm8"
      },
      "outputs": [],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HG8OCXSIGLQ"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-LhllLN-5ph"
      },
      "outputs": [],
      "source": [
        "#@title install dependencies\n",
        "! git clone https://github.com/ashawkey/stable-dreamfusion.git\n",
        "\n",
        "%cd stable-dreamfusion\n",
        "\n",
        "# install requirements\n",
        "! pip install -r requirements.txt\n",
        "! pip install git+https://github.com/NVlabs/nvdiffrast/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWwVGf9NNQnv"
      },
      "outputs": [],
      "source": [
        "#@title login to huggingface to download stable diffusion (also need to accpet the conditions for stable-diffusion)\n",
        "from huggingface_hub import notebook_login\n",
        "from google.colab import output\n",
        "\n",
        "output.enable_custom_widget_manager()\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VklXFNisIrDo"
      },
      "source": [
        "### Training & Testing\n",
        "* First time training will take some time to build the CUDA extensions.\n",
        "* It takes about 0.7s per training step, so the default 5000 training steps take around 1 hour to finish. A larger `Training_iters` usually leads to better results.\n",
        "* If CUDA OOM, try to decrease `Max_steps` and `Training_nerf_resolution`.\n",
        "* If the NeRF fails to learn anything (empty scene, only background), try to decrease `Lambda_entropy` which regularizes the learned opacity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "M4WGvOBBI1ae"
      },
      "outputs": [],
      "source": [
        "#@markdown ####**Training Settings:**\n",
        "Prompt_text = \"a DSLR photo of a dog in a top hat riding a bike\\\"\" #@param {type: 'string'}\n",
        "Training_iters = 50000 #@param {type: 'integer'}\n",
        "Learning_rate = 1e-3 #@param {type: 'number'}\n",
        "Training_nerf_resolution = 64  #@param {type: 'integer'}\n",
        "# CUDA_ray = True #@param {type: 'boolean'}\n",
        "# View_dependent_prompt = True #@param {type: 'boolean'}\n",
        "# FP16 = True #@param {type: 'boolean'}\n",
        "Seed = 0 #@param {type: 'integer'}\n",
        "Lambda_entropy = 1e-4 #@param {type: 'number'}\n",
        "Max_steps = 512 #@param {type: 'number'}\n",
        "Checkpoint = 'latest' #@param {type: 'string'}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ####**Output Settings:**\n",
        "Workspace = \"trial\" #@param{type: 'string'}\n",
        "# Save_mesh = True #@param {type: 'boolean'}\n",
        "\n",
        "# processings\n",
        "Prompt_text = \"'\" + Prompt_text + \"'\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHHjlAkwJDa5"
      },
      "outputs": [],
      "source": [
        "#@title start training\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "%run main.py -O --text {Prompt_text} --workspace {Workspace} --iters {Training_iters} --lr {Learning_rate} --w {Training_nerf_resolution} --h {Training_nerf_resolution} --seed {Seed} --lambda_entropy {Lambda_entropy} --ckpt {Checkpoint} --save_mesh --max_steps {Max_steps}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJ6-1tkaRTpy"
      },
      "outputs": [],
      "source": [
        "#@markdown ####**Testing Settings:**\n",
        "\n",
        "Workspace_test = \"trial\" #@param{type: 'string'}\n",
        "# Save_mesh = True #@param {type: 'boolean'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6liVfcPZRGWD"
      },
      "outputs": [],
      "source": [
        "#@title testing \n",
        "%run main.py -O --test --workspace {Workspace_test} --save_mesh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxzEhYT5PQIV"
      },
      "source": [
        "### Display results\n",
        "* RGB and Depth video are located at `{Workspace}/results/*.mp4`\n",
        "* Mesh is under `{Workspace}/mesh/`, you could see three files named `mesh.obj`, `mesh.mtl`, and `albedo.png`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmmiVeUDOXI6"
      },
      "outputs": [],
      "source": [
        "#@title display RGB video\n",
        "import os\n",
        "import glob\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "def get_latest_file(path):\n",
        "  dir_list = glob.glob(path)\n",
        "  dir_list.sort(key=lambda x: os.path.getmtime(x))\n",
        "  return dir_list[-1]\n",
        "\n",
        "def show_video(video_path, video_width = 600):\n",
        "   \n",
        "  video_file = open(video_path, \"r+b\").read()\n",
        "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "\n",
        "  return HTML(f\"\"\"<video width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")\n",
        " \n",
        "rgb_video = get_latest_file(os.path.join(Workspace, 'results', '*_rgb.mp4'))\n",
        "show_video(rgb_video)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "private_outputs": true,
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}